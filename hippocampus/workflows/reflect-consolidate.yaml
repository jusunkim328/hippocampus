name: reflect-consolidate
description: 에피소드 기억을 통합하여 의미 기억으로 승격
enabled: true
tags: ["hippocampus", "reflect"]
triggers:
  - type: scheduled
    every: 6h
steps:
  - name: gather_unreflected
    type: elasticsearch.search
    with:
      index: episodic-memories
      body:
        query:
          bool:
            must:
              - term:
                  reflected: false
        sort:
          - timestamp: desc
        size: 50

  - name: consolidate
    type: ai.completion
    with:
      prompt: |
        다음 에피소드 기억들을 분석하여 핵심 교훈과 패턴을 추출하라.

        ## 지시사항
        1. 관련 에피소드를 클러스터링하라
        2. 각 클러스터에서 핵심 교훈/패턴을 SPO(Subject-Predicate-Object) 형태로 추출하라
           - entity: 주어 (서비스명, 시스템명)
           - attribute: 술어 (설정, 원인, 해결방법)
           - value: 목적어 (구체적 값, 설명)
        3. 기존 semantic-memories와 중복되면 update_count를 증가시켜라
        4. 각 SPO에 confidence(0.0-1.0)와 category를 부여하라

        ## 에피소드 데이터
        {{ steps.gather_unreflected.output }}

        ## 출력 형식 (JSON 배열)
        [
          {
            "entity": "서비스명",
            "attribute": "속성명",
            "value": "구체적 값",
            "confidence": 0.8,
            "category": "도메인명",
            "raw_text": "요약 텍스트",
            "source_conversation_ids": ["관련 대화 ID 목록"],
            "update_count": 1
          }
        ]

  - name: store_consolidated
    type: elasticsearch.bulk
    with:
      index: semantic-memories
      documents: "{{ steps.consolidate.output }}"
      template:
        content: "{{ entity }} {{ attribute }} {{ value }}"
        first_observed: "{{ now }}"
        last_updated: "{{ now }}"

  - name: mark_reflected
    type: elasticsearch.update_by_query
    with:
      index: episodic-memories
      query:
        bool:
          must:
            - term:
                reflected: false
      script:
        source: "ctx._source.reflected = true"
        lang: painless
